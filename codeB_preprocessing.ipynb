{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking wich is the best preprocessing methods combo - Binary Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset\n",
    "path_2 = \"datasets/diabetes_binary_health_indicators_BRFSS2015.csv\"\n",
    "\n",
    "df = pd.read_csv(path_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Dataset preprocessing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining duplicates: 0.\n",
      "Before balancing: Counter({0.0: 194377, 1.0: 35097})\n",
      "[Binary] After Undersampling: Counter({0.0: 60000, 1.0: 28076})\n",
      "[Binary] After SMOTE ENN: Counter({0.0: 30929, 1.0: 17534})\n",
      "[Binary] After TomekLinks: Counter({0.0: 30909, 1.0: 17534})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but LinearSVC was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - Precision: 0.6589 - Recall: 0.7154 - accuracy: 0.8687 - loss: 0.3035 - val_Precision: 1.0000 - val_Recall: 0.8687 - val_accuracy: 0.8687 - val_loss: 0.3471\n",
      "Epoch 2/20\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.7987 - Recall: 0.8778 - accuracy: 0.9289 - loss: 0.1869 - val_Precision: 1.0000 - val_Recall: 0.8470 - val_accuracy: 0.8470 - val_loss: 0.3738\n",
      "Epoch 3/20\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8063 - Recall: 0.8730 - accuracy: 0.9329 - loss: 0.1797 - val_Precision: 1.0000 - val_Recall: 0.8479 - val_accuracy: 0.8479 - val_loss: 0.3580\n",
      "Epoch 4/20\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8034 - Recall: 0.8744 - accuracy: 0.9317 - loss: 0.1776 - val_Precision: 1.0000 - val_Recall: 0.8504 - val_accuracy: 0.8504 - val_loss: 0.3606\n",
      "Epoch 5/20\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8160 - Recall: 0.8796 - accuracy: 0.9351 - loss: 0.1747 - val_Precision: 1.0000 - val_Recall: 0.8435 - val_accuracy: 0.8435 - val_loss: 0.3786\n",
      "Epoch 6/20\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8140 - Recall: 0.8725 - accuracy: 0.9337 - loss: 0.1755 - val_Precision: 1.0000 - val_Recall: 0.8435 - val_accuracy: 0.8435 - val_loss: 0.3781\n",
      "Epoch 7/20\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8176 - Recall: 0.8760 - accuracy: 0.9356 - loss: 0.1678 - val_Precision: 1.0000 - val_Recall: 0.8409 - val_accuracy: 0.8409 - val_loss: 0.3721\n",
      "Epoch 8/20\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8190 - Recall: 0.8771 - accuracy: 0.9370 - loss: 0.1656 - val_Precision: 1.0000 - val_Recall: 0.8470 - val_accuracy: 0.8470 - val_loss: 0.3519\n",
      "Epoch 9/20\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8234 - Recall: 0.8781 - accuracy: 0.9369 - loss: 0.1656 - val_Precision: 1.0000 - val_Recall: 0.8479 - val_accuracy: 0.8479 - val_loss: 0.3554\n",
      "Epoch 10/20\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8287 - Recall: 0.8773 - accuracy: 0.9383 - loss: 0.1666 - val_Precision: 1.0000 - val_Recall: 0.8551 - val_accuracy: 0.8551 - val_loss: 0.3399\n",
      "Epoch 11/20\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8210 - Recall: 0.8790 - accuracy: 0.9369 - loss: 0.1663 - val_Precision: 1.0000 - val_Recall: 0.8387 - val_accuracy: 0.8387 - val_loss: 0.3676\n",
      "Epoch 12/20\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8210 - Recall: 0.8724 - accuracy: 0.9358 - loss: 0.1659 - val_Precision: 1.0000 - val_Recall: 0.8272 - val_accuracy: 0.8272 - val_loss: 0.4053\n",
      "Epoch 13/20\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8201 - Recall: 0.8685 - accuracy: 0.9358 - loss: 0.1681 - val_Precision: 1.0000 - val_Recall: 0.8437 - val_accuracy: 0.8437 - val_loss: 0.3668\n",
      "Epoch 14/20\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8311 - Recall: 0.8815 - accuracy: 0.9390 - loss: 0.1627 - val_Precision: 1.0000 - val_Recall: 0.8346 - val_accuracy: 0.8346 - val_loss: 0.3904\n",
      "Epoch 15/20\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8159 - Recall: 0.8662 - accuracy: 0.9343 - loss: 0.1711 - val_Precision: 1.0000 - val_Recall: 0.8320 - val_accuracy: 0.8320 - val_loss: 0.3813\n",
      "Epoch 16/20\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8271 - Recall: 0.8722 - accuracy: 0.9372 - loss: 0.1674 - val_Precision: 1.0000 - val_Recall: 0.8429 - val_accuracy: 0.8429 - val_loss: 0.3554\n",
      "Epoch 17/20\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8274 - Recall: 0.8749 - accuracy: 0.9369 - loss: 0.1659 - val_Precision: 1.0000 - val_Recall: 0.8299 - val_accuracy: 0.8299 - val_loss: 0.3826\n",
      "Epoch 18/20\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8336 - Recall: 0.8706 - accuracy: 0.9394 - loss: 0.1665 - val_Precision: 1.0000 - val_Recall: 0.8377 - val_accuracy: 0.8377 - val_loss: 0.3448\n",
      "Epoch 19/20\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8322 - Recall: 0.8729 - accuracy: 0.9377 - loss: 0.1691 - val_Precision: 1.0000 - val_Recall: 0.8288 - val_accuracy: 0.8288 - val_loss: 0.3823\n",
      "Epoch 20/20\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8440 - Recall: 0.8719 - accuracy: 0.9419 - loss: 0.1609 - val_Precision: 1.0000 - val_Recall: 0.8276 - val_accuracy: 0.8276 - val_loss: 0.3939\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769us/step\n",
      "[Binary] After Undersampling: Counter({0.0: 60000, 1.0: 28086})\n",
      "[Binary] After SMOTE ENN: Counter({0.0: 31003, 1.0: 17538})\n",
      "[Binary] After TomekLinks: Counter({0.0: 30978, 1.0: 17538})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but LinearSVC was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1213/1213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - Precision: 0.6791 - Recall: 0.6269 - accuracy: 0.8721 - loss: 0.3126 - val_Precision: 1.0000 - val_Recall: 0.8711 - val_accuracy: 0.8711 - val_loss: 0.3783\n",
      "Epoch 2/20\n",
      "\u001b[1m1213/1213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.7877 - Recall: 0.8848 - accuracy: 0.9289 - loss: 0.1841 - val_Precision: 1.0000 - val_Recall: 0.8472 - val_accuracy: 0.8472 - val_loss: 0.3903\n",
      "Epoch 3/20\n",
      "\u001b[1m1213/1213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8024 - Recall: 0.8800 - accuracy: 0.9320 - loss: 0.1773 - val_Precision: 1.0000 - val_Recall: 0.8571 - val_accuracy: 0.8571 - val_loss: 0.3739\n",
      "Epoch 4/20\n",
      "\u001b[1m1213/1213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8127 - Recall: 0.8815 - accuracy: 0.9361 - loss: 0.1696 - val_Precision: 1.0000 - val_Recall: 0.8692 - val_accuracy: 0.8692 - val_loss: 0.3369\n",
      "Epoch 5/20\n",
      "\u001b[1m1213/1213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8165 - Recall: 0.8844 - accuracy: 0.9370 - loss: 0.1671 - val_Precision: 1.0000 - val_Recall: 0.8556 - val_accuracy: 0.8556 - val_loss: 0.3861\n",
      "Epoch 6/20\n",
      "\u001b[1m1213/1213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8265 - Recall: 0.8885 - accuracy: 0.9396 - loss: 0.1564 - val_Precision: 1.0000 - val_Recall: 0.8577 - val_accuracy: 0.8577 - val_loss: 0.3809\n",
      "Epoch 7/20\n",
      "\u001b[1m1213/1213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8226 - Recall: 0.8909 - accuracy: 0.9389 - loss: 0.1623 - val_Precision: 1.0000 - val_Recall: 0.8419 - val_accuracy: 0.8419 - val_loss: 0.3983\n",
      "Epoch 8/20\n",
      "\u001b[1m1213/1213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8350 - Recall: 0.8811 - accuracy: 0.9404 - loss: 0.1590 - val_Precision: 1.0000 - val_Recall: 0.8507 - val_accuracy: 0.8507 - val_loss: 0.3791\n",
      "Epoch 9/20\n",
      "\u001b[1m1213/1213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8316 - Recall: 0.8893 - accuracy: 0.9417 - loss: 0.1567 - val_Precision: 1.0000 - val_Recall: 0.8462 - val_accuracy: 0.8462 - val_loss: 0.3900\n",
      "Epoch 10/20\n",
      "\u001b[1m1213/1213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8330 - Recall: 0.8863 - accuracy: 0.9405 - loss: 0.1604 - val_Precision: 1.0000 - val_Recall: 0.8384 - val_accuracy: 0.8384 - val_loss: 0.4040\n",
      "Epoch 11/20\n",
      "\u001b[1m1213/1213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8343 - Recall: 0.8856 - accuracy: 0.9420 - loss: 0.1546 - val_Precision: 1.0000 - val_Recall: 0.8472 - val_accuracy: 0.8472 - val_loss: 0.3827\n",
      "Epoch 12/20\n",
      "\u001b[1m1213/1213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8341 - Recall: 0.8881 - accuracy: 0.9412 - loss: 0.1585 - val_Precision: 1.0000 - val_Recall: 0.8408 - val_accuracy: 0.8408 - val_loss: 0.3849\n",
      "Epoch 13/20\n",
      "\u001b[1m1213/1213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8365 - Recall: 0.8832 - accuracy: 0.9420 - loss: 0.1574 - val_Precision: 1.0000 - val_Recall: 0.8386 - val_accuracy: 0.8386 - val_loss: 0.4040\n",
      "Epoch 14/20\n",
      "\u001b[1m1213/1213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8336 - Recall: 0.8828 - accuracy: 0.9411 - loss: 0.1560 - val_Precision: 1.0000 - val_Recall: 0.8526 - val_accuracy: 0.8526 - val_loss: 0.3670\n",
      "Epoch 15/20\n",
      "\u001b[1m1213/1213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8326 - Recall: 0.8807 - accuracy: 0.9396 - loss: 0.1573 - val_Precision: 1.0000 - val_Recall: 0.8437 - val_accuracy: 0.8437 - val_loss: 0.4099\n",
      "Epoch 16/20\n",
      "\u001b[1m1213/1213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8381 - Recall: 0.8833 - accuracy: 0.9418 - loss: 0.1510 - val_Precision: 1.0000 - val_Recall: 0.8524 - val_accuracy: 0.8524 - val_loss: 0.3506\n",
      "Epoch 17/20\n",
      "\u001b[1m1213/1213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8368 - Recall: 0.8879 - accuracy: 0.9422 - loss: 0.1501 - val_Precision: 1.0000 - val_Recall: 0.8531 - val_accuracy: 0.8531 - val_loss: 0.3539\n",
      "Epoch 18/20\n",
      "\u001b[1m1213/1213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8366 - Recall: 0.8883 - accuracy: 0.9418 - loss: 0.1549 - val_Precision: 1.0000 - val_Recall: 0.8489 - val_accuracy: 0.8489 - val_loss: 0.3865\n",
      "Epoch 19/20\n",
      "\u001b[1m1213/1213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8394 - Recall: 0.8867 - accuracy: 0.9427 - loss: 0.1537 - val_Precision: 1.0000 - val_Recall: 0.8458 - val_accuracy: 0.8458 - val_loss: 0.3969\n",
      "Epoch 20/20\n",
      "\u001b[1m1213/1213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8302 - Recall: 0.8867 - accuracy: 0.9406 - loss: 0.1561 - val_Precision: 1.0000 - val_Recall: 0.8482 - val_accuracy: 0.8482 - val_loss: 0.3619\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step\n",
      "[Binary] After Undersampling: Counter({0.0: 60000, 1.0: 28253})\n",
      "[Binary] After SMOTE ENN: Counter({0.0: 31045, 1.0: 17385})\n",
      "[Binary] After TomekLinks: Counter({0.0: 31018, 1.0: 17385})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but LinearSVC was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1211/1211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - Precision: 0.6258 - Recall: 0.7721 - accuracy: 0.8440 - loss: 0.3177 - val_Precision: 1.0000 - val_Recall: 0.8474 - val_accuracy: 0.8474 - val_loss: 0.3916\n",
      "Epoch 2/20\n",
      "\u001b[1m1211/1211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.7970 - Recall: 0.8712 - accuracy: 0.9305 - loss: 0.1828 - val_Precision: 1.0000 - val_Recall: 0.8512 - val_accuracy: 0.8512 - val_loss: 0.3711\n",
      "Epoch 3/20\n",
      "\u001b[1m1211/1211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.7979 - Recall: 0.8784 - accuracy: 0.9299 - loss: 0.1781 - val_Precision: 1.0000 - val_Recall: 0.8481 - val_accuracy: 0.8481 - val_loss: 0.3573\n",
      "Epoch 4/20\n",
      "\u001b[1m1211/1211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8124 - Recall: 0.8750 - accuracy: 0.9338 - loss: 0.1701 - val_Precision: 1.0000 - val_Recall: 0.8317 - val_accuracy: 0.8317 - val_loss: 0.3703\n",
      "Epoch 5/20\n",
      "\u001b[1m1211/1211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8104 - Recall: 0.8729 - accuracy: 0.9328 - loss: 0.1742 - val_Precision: 1.0000 - val_Recall: 0.8436 - val_accuracy: 0.8436 - val_loss: 0.3779\n",
      "Epoch 6/20\n",
      "\u001b[1m1211/1211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8149 - Recall: 0.8781 - accuracy: 0.9365 - loss: 0.1649 - val_Precision: 1.0000 - val_Recall: 0.8471 - val_accuracy: 0.8471 - val_loss: 0.3593\n",
      "Epoch 7/20\n",
      "\u001b[1m1211/1211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8174 - Recall: 0.8729 - accuracy: 0.9363 - loss: 0.1690 - val_Precision: 1.0000 - val_Recall: 0.8424 - val_accuracy: 0.8424 - val_loss: 0.3761\n",
      "Epoch 8/20\n",
      "\u001b[1m1211/1211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8201 - Recall: 0.8815 - accuracy: 0.9372 - loss: 0.1633 - val_Precision: 1.0000 - val_Recall: 0.8499 - val_accuracy: 0.8499 - val_loss: 0.3570\n",
      "Epoch 9/20\n",
      "\u001b[1m1211/1211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8157 - Recall: 0.8762 - accuracy: 0.9360 - loss: 0.1660 - val_Precision: 1.0000 - val_Recall: 0.8341 - val_accuracy: 0.8341 - val_loss: 0.3700\n",
      "Epoch 10/20\n",
      "\u001b[1m1211/1211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8178 - Recall: 0.8705 - accuracy: 0.9354 - loss: 0.1667 - val_Precision: 1.0000 - val_Recall: 0.8452 - val_accuracy: 0.8452 - val_loss: 0.3439\n",
      "Epoch 11/20\n",
      "\u001b[1m1211/1211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8237 - Recall: 0.8781 - accuracy: 0.9382 - loss: 0.1598 - val_Precision: 1.0000 - val_Recall: 0.8340 - val_accuracy: 0.8340 - val_loss: 0.3679\n",
      "Epoch 12/20\n",
      "\u001b[1m1211/1211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8268 - Recall: 0.8631 - accuracy: 0.9374 - loss: 0.1605 - val_Precision: 1.0000 - val_Recall: 0.8368 - val_accuracy: 0.8368 - val_loss: 0.3551\n",
      "Epoch 13/20\n",
      "\u001b[1m1211/1211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8238 - Recall: 0.8753 - accuracy: 0.9379 - loss: 0.1604 - val_Precision: 1.0000 - val_Recall: 0.8331 - val_accuracy: 0.8331 - val_loss: 0.3622\n",
      "Epoch 14/20\n",
      "\u001b[1m1211/1211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8333 - Recall: 0.8721 - accuracy: 0.9387 - loss: 0.1616 - val_Precision: 1.0000 - val_Recall: 0.8383 - val_accuracy: 0.8383 - val_loss: 0.3598\n",
      "Epoch 15/20\n",
      "\u001b[1m1211/1211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8318 - Recall: 0.8662 - accuracy: 0.9373 - loss: 0.1620 - val_Precision: 1.0000 - val_Recall: 0.8447 - val_accuracy: 0.8447 - val_loss: 0.3399\n",
      "Epoch 16/20\n",
      "\u001b[1m1211/1211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8290 - Recall: 0.8765 - accuracy: 0.9390 - loss: 0.1572 - val_Precision: 1.0000 - val_Recall: 0.8444 - val_accuracy: 0.8444 - val_loss: 0.3358\n",
      "Epoch 17/20\n",
      "\u001b[1m1211/1211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8332 - Recall: 0.8724 - accuracy: 0.9397 - loss: 0.1589 - val_Precision: 1.0000 - val_Recall: 0.8407 - val_accuracy: 0.8407 - val_loss: 0.3548\n",
      "Epoch 18/20\n",
      "\u001b[1m1211/1211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8316 - Recall: 0.8732 - accuracy: 0.9394 - loss: 0.1607 - val_Precision: 1.0000 - val_Recall: 0.8319 - val_accuracy: 0.8319 - val_loss: 0.3514\n",
      "Epoch 19/20\n",
      "\u001b[1m1211/1211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8365 - Recall: 0.8632 - accuracy: 0.9392 - loss: 0.1613 - val_Precision: 1.0000 - val_Recall: 0.8369 - val_accuracy: 0.8369 - val_loss: 0.3675\n",
      "Epoch 20/20\n",
      "\u001b[1m1211/1211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8338 - Recall: 0.8710 - accuracy: 0.9393 - loss: 0.1593 - val_Precision: 1.0000 - val_Recall: 0.8518 - val_accuracy: 0.8518 - val_loss: 0.3333\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step\n",
      "[Binary] After Undersampling: Counter({0.0: 60000, 1.0: 28087})\n",
      "[Binary] After SMOTE ENN: Counter({0.0: 31161, 1.0: 17605})\n",
      "[Binary] After TomekLinks: Counter({0.0: 31140, 1.0: 17605})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but LinearSVC was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1219/1219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - Precision: 0.6527 - Recall: 0.7802 - accuracy: 0.8622 - loss: 0.3042 - val_Precision: 1.0000 - val_Recall: 0.8529 - val_accuracy: 0.8529 - val_loss: 0.4065\n",
      "Epoch 2/20\n",
      "\u001b[1m1219/1219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8033 - Recall: 0.8830 - accuracy: 0.9324 - loss: 0.1799 - val_Precision: 1.0000 - val_Recall: 0.8577 - val_accuracy: 0.8577 - val_loss: 0.3746\n",
      "Epoch 3/20\n",
      "\u001b[1m1219/1219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8029 - Recall: 0.8911 - accuracy: 0.9347 - loss: 0.1743 - val_Precision: 1.0000 - val_Recall: 0.8551 - val_accuracy: 0.8551 - val_loss: 0.3826\n",
      "Epoch 4/20\n",
      "\u001b[1m1219/1219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8286 - Recall: 0.8892 - accuracy: 0.9404 - loss: 0.1644 - val_Precision: 1.0000 - val_Recall: 0.8401 - val_accuracy: 0.8401 - val_loss: 0.4129\n",
      "Epoch 5/20\n",
      "\u001b[1m1219/1219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8305 - Recall: 0.8938 - accuracy: 0.9412 - loss: 0.1600 - val_Precision: 1.0000 - val_Recall: 0.8532 - val_accuracy: 0.8532 - val_loss: 0.3656\n",
      "Epoch 6/20\n",
      "\u001b[1m1219/1219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8300 - Recall: 0.8927 - accuracy: 0.9414 - loss: 0.1590 - val_Precision: 1.0000 - val_Recall: 0.8516 - val_accuracy: 0.8516 - val_loss: 0.3636\n",
      "Epoch 7/20\n",
      "\u001b[1m1219/1219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8277 - Recall: 0.8872 - accuracy: 0.9405 - loss: 0.1568 - val_Precision: 1.0000 - val_Recall: 0.8541 - val_accuracy: 0.8541 - val_loss: 0.3575\n",
      "Epoch 8/20\n",
      "\u001b[1m1219/1219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8303 - Recall: 0.8924 - accuracy: 0.9412 - loss: 0.1613 - val_Precision: 1.0000 - val_Recall: 0.8623 - val_accuracy: 0.8623 - val_loss: 0.3541\n",
      "Epoch 9/20\n",
      "\u001b[1m1219/1219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8343 - Recall: 0.8990 - accuracy: 0.9424 - loss: 0.1573 - val_Precision: 1.0000 - val_Recall: 0.8488 - val_accuracy: 0.8488 - val_loss: 0.3763\n",
      "Epoch 10/20\n",
      "\u001b[1m1219/1219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8336 - Recall: 0.8851 - accuracy: 0.9411 - loss: 0.1589 - val_Precision: 1.0000 - val_Recall: 0.8474 - val_accuracy: 0.8474 - val_loss: 0.3546\n",
      "Epoch 11/20\n",
      "\u001b[1m1219/1219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8381 - Recall: 0.8891 - accuracy: 0.9434 - loss: 0.1567 - val_Precision: 1.0000 - val_Recall: 0.8556 - val_accuracy: 0.8556 - val_loss: 0.3492\n",
      "Epoch 12/20\n",
      "\u001b[1m1219/1219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8363 - Recall: 0.8855 - accuracy: 0.9434 - loss: 0.1548 - val_Precision: 1.0000 - val_Recall: 0.8485 - val_accuracy: 0.8485 - val_loss: 0.3873\n",
      "Epoch 13/20\n",
      "\u001b[1m1219/1219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8384 - Recall: 0.8830 - accuracy: 0.9425 - loss: 0.1567 - val_Precision: 1.0000 - val_Recall: 0.8529 - val_accuracy: 0.8529 - val_loss: 0.3563\n",
      "Epoch 14/20\n",
      "\u001b[1m1219/1219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8384 - Recall: 0.8910 - accuracy: 0.9427 - loss: 0.1537 - val_Precision: 1.0000 - val_Recall: 0.8449 - val_accuracy: 0.8449 - val_loss: 0.3573\n",
      "Epoch 15/20\n",
      "\u001b[1m1219/1219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8431 - Recall: 0.8851 - accuracy: 0.9431 - loss: 0.1553 - val_Precision: 1.0000 - val_Recall: 0.8400 - val_accuracy: 0.8400 - val_loss: 0.3876\n",
      "Epoch 16/20\n",
      "\u001b[1m1219/1219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8431 - Recall: 0.8847 - accuracy: 0.9422 - loss: 0.1566 - val_Precision: 1.0000 - val_Recall: 0.8411 - val_accuracy: 0.8411 - val_loss: 0.3602\n",
      "Epoch 17/20\n",
      "\u001b[1m1219/1219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8446 - Recall: 0.8859 - accuracy: 0.9439 - loss: 0.1569 - val_Precision: 1.0000 - val_Recall: 0.8425 - val_accuracy: 0.8425 - val_loss: 0.3662\n",
      "Epoch 18/20\n",
      "\u001b[1m1219/1219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8433 - Recall: 0.8812 - accuracy: 0.9431 - loss: 0.1547 - val_Precision: 1.0000 - val_Recall: 0.8422 - val_accuracy: 0.8422 - val_loss: 0.3814\n",
      "Epoch 19/20\n",
      "\u001b[1m1219/1219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8444 - Recall: 0.8883 - accuracy: 0.9446 - loss: 0.1556 - val_Precision: 1.0000 - val_Recall: 0.8418 - val_accuracy: 0.8418 - val_loss: 0.3664\n",
      "Epoch 20/20\n",
      "\u001b[1m1219/1219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8454 - Recall: 0.8901 - accuracy: 0.9452 - loss: 0.1503 - val_Precision: 1.0000 - val_Recall: 0.8490 - val_accuracy: 0.8490 - val_loss: 0.3430\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step\n",
      "[Binary] After Undersampling: Counter({0.0: 60000, 1.0: 27953})\n",
      "[Binary] After SMOTE ENN: Counter({0.0: 31195, 1.0: 17784})\n",
      "[Binary] After TomekLinks: Counter({0.0: 31174, 1.0: 17784})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but LinearSVC was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1224/1224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - Precision: 0.6625 - Recall: 0.7391 - accuracy: 0.8657 - loss: 0.3053 - val_Precision: 1.0000 - val_Recall: 0.8713 - val_accuracy: 0.8713 - val_loss: 0.3512\n",
      "Epoch 2/20\n",
      "\u001b[1m1224/1224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.7956 - Recall: 0.8856 - accuracy: 0.9291 - loss: 0.1881 - val_Precision: 1.0000 - val_Recall: 0.8656 - val_accuracy: 0.8656 - val_loss: 0.3427\n",
      "Epoch 3/20\n",
      "\u001b[1m1224/1224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8088 - Recall: 0.8810 - accuracy: 0.9329 - loss: 0.1831 - val_Precision: 1.0000 - val_Recall: 0.8589 - val_accuracy: 0.8589 - val_loss: 0.3498\n",
      "Epoch 4/20\n",
      "\u001b[1m1224/1224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8185 - Recall: 0.8821 - accuracy: 0.9365 - loss: 0.1725 - val_Precision: 1.0000 - val_Recall: 0.8461 - val_accuracy: 0.8461 - val_loss: 0.3822\n",
      "Epoch 5/20\n",
      "\u001b[1m1224/1224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8278 - Recall: 0.8892 - accuracy: 0.9395 - loss: 0.1668 - val_Precision: 1.0000 - val_Recall: 0.8440 - val_accuracy: 0.8440 - val_loss: 0.3756\n",
      "Epoch 6/20\n",
      "\u001b[1m1224/1224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8292 - Recall: 0.8751 - accuracy: 0.9377 - loss: 0.1676 - val_Precision: 1.0000 - val_Recall: 0.8455 - val_accuracy: 0.8455 - val_loss: 0.3777\n",
      "Epoch 7/20\n",
      "\u001b[1m1224/1224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8253 - Recall: 0.8794 - accuracy: 0.9378 - loss: 0.1685 - val_Precision: 1.0000 - val_Recall: 0.8573 - val_accuracy: 0.8573 - val_loss: 0.3294\n",
      "Epoch 8/20\n",
      "\u001b[1m1224/1224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8303 - Recall: 0.8898 - accuracy: 0.9410 - loss: 0.1609 - val_Precision: 1.0000 - val_Recall: 0.8446 - val_accuracy: 0.8446 - val_loss: 0.3752\n",
      "Epoch 9/20\n",
      "\u001b[1m1224/1224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8317 - Recall: 0.8832 - accuracy: 0.9388 - loss: 0.1665 - val_Precision: 1.0000 - val_Recall: 0.8428 - val_accuracy: 0.8428 - val_loss: 0.3813\n",
      "Epoch 10/20\n",
      "\u001b[1m1224/1224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8336 - Recall: 0.8768 - accuracy: 0.9389 - loss: 0.1662 - val_Precision: 1.0000 - val_Recall: 0.8368 - val_accuracy: 0.8368 - val_loss: 0.3824\n",
      "Epoch 11/20\n",
      "\u001b[1m1224/1224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8423 - Recall: 0.8835 - accuracy: 0.9416 - loss: 0.1601 - val_Precision: 1.0000 - val_Recall: 0.8418 - val_accuracy: 0.8418 - val_loss: 0.3585\n",
      "Epoch 12/20\n",
      "\u001b[1m1224/1224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8436 - Recall: 0.8813 - accuracy: 0.9416 - loss: 0.1614 - val_Precision: 1.0000 - val_Recall: 0.8428 - val_accuracy: 0.8428 - val_loss: 0.3560\n",
      "Epoch 13/20\n",
      "\u001b[1m1224/1224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8365 - Recall: 0.8784 - accuracy: 0.9410 - loss: 0.1588 - val_Precision: 1.0000 - val_Recall: 0.8374 - val_accuracy: 0.8374 - val_loss: 0.3756\n",
      "Epoch 14/20\n",
      "\u001b[1m1224/1224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8418 - Recall: 0.8840 - accuracy: 0.9419 - loss: 0.1583 - val_Precision: 1.0000 - val_Recall: 0.8445 - val_accuracy: 0.8445 - val_loss: 0.3547\n",
      "Epoch 15/20\n",
      "\u001b[1m1224/1224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8422 - Recall: 0.8830 - accuracy: 0.9417 - loss: 0.1613 - val_Precision: 1.0000 - val_Recall: 0.8316 - val_accuracy: 0.8316 - val_loss: 0.3905\n",
      "Epoch 16/20\n",
      "\u001b[1m1224/1224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8444 - Recall: 0.8773 - accuracy: 0.9419 - loss: 0.1599 - val_Precision: 1.0000 - val_Recall: 0.8439 - val_accuracy: 0.8439 - val_loss: 0.3725\n",
      "Epoch 17/20\n",
      "\u001b[1m1224/1224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8456 - Recall: 0.8836 - accuracy: 0.9424 - loss: 0.1592 - val_Precision: 1.0000 - val_Recall: 0.8434 - val_accuracy: 0.8434 - val_loss: 0.3551\n",
      "Epoch 18/20\n",
      "\u001b[1m1224/1224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - Precision: 0.8507 - Recall: 0.8845 - accuracy: 0.9442 - loss: 0.1589 - val_Precision: 1.0000 - val_Recall: 0.8353 - val_accuracy: 0.8353 - val_loss: 0.3889\n",
      "Epoch 19/20\n",
      "\u001b[1m1224/1224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8529 - Recall: 0.8854 - accuracy: 0.9452 - loss: 0.1519 - val_Precision: 1.0000 - val_Recall: 0.8464 - val_accuracy: 0.8464 - val_loss: 0.3370\n",
      "Epoch 20/20\n",
      "\u001b[1m1224/1224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Precision: 0.8434 - Recall: 0.8837 - accuracy: 0.9427 - loss: 0.1596 - val_Precision: 1.0000 - val_Recall: 0.8479 - val_accuracy: 0.8479 - val_loss: 0.3413\n",
      "\u001b[1m1435/1435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step\n",
      "{'NN': {'F1': np.float64(0.3),\n",
      "        'Precision': np.float64(0.17),\n",
      "        'Recall': np.float64(0.97)},\n",
      " 'RF': {'F1': np.float64(0.26),\n",
      "        'Precision': np.float64(0.15),\n",
      "        'Recall': np.float64(1.0)},\n",
      " 'SVM': {'F1': np.float64(0.26),\n",
      "         'Precision': np.float64(0.15),\n",
      "         'Recall': np.float64(1.0)}}\n"
     ]
    }
   ],
   "source": [
    "# Removing duplicates\n",
    "\n",
    "df.drop_duplicates(inplace = True)\n",
    "print(f\"Remaining duplicates: {df.duplicated().sum()}.\")\n",
    "\n",
    "# Droping columns that are not relevant for the model\n",
    "\n",
    "columns = [\"PhysHlth\",\"Veggies\",\"NoDocbcCost\"]\n",
    "df = df.drop(columns=columns)\n",
    "\n",
    "# PREPARING THE DATA BEFORE AND AFTER THE DATA SPLITTING\n",
    "\n",
    "# Checking the class distribution before balancing\n",
    "print(\"Before balancing:\", Counter(df['Diabetes_binary']))\n",
    "\n",
    "X = df.drop(columns=['Diabetes_binary'])\n",
    "y = df['Diabetes_binary']\n",
    "\n",
    "\n",
    "f1s_svm, precisions_svm, recalls_svm = [], [], []\n",
    "f1s_rf, precisions_rf, recalls_rf = [], [], []\n",
    "f1s_nn, precisions_nn, recalls_nn = [], [], []\n",
    "\n",
    "n_runs = 5\n",
    "for run in range(n_runs):\n",
    "\n",
    "    # Spltting the data\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=run)\n",
    "\n",
    "    # Doing Normalization after splitting to avoid data leakage\n",
    "\n",
    "    #scaler = MinMaxScaler()\n",
    "    #X_train_scaled = scaler.fit_transform(X_train)\n",
    "    #X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Doing Standardization \n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Random Undersampling\n",
    "\n",
    "    undersample = RandomUnderSampler(sampling_strategy={0.0:60000}, random_state=run)\n",
    "    X_und, y_und = undersample.fit_resample(X_train_scaled, y_train)\n",
    "    print(\"[Binary] After Undersampling:\", Counter(y_und))\n",
    "\n",
    "    # SMOTE ENN for oversampling/downsampling\n",
    "\n",
    "    smote_enn = SMOTEENN(random_state=run, n_jobs=-1, sampling_strategy=0.7)\n",
    "    X_und, y_und = smote_enn.fit_resample(X_und, y_und)\n",
    "    print(\"[Binary] After SMOTE ENN:\", Counter(y_und))\n",
    "\n",
    "\n",
    "    # SMOTE for Oversampling\n",
    "\n",
    "    #smote = SMOTE(random_state=run, sampling_strategy=0.7)\n",
    "    #X_und, y_und = smote.fit_resample(X_und, y_und)\n",
    "    #print(\"[Binary] After SMOTE:\", Counter(y_und))\n",
    "\n",
    "    # Tomek Links\n",
    "\n",
    "    tomek = TomekLinks()\n",
    "    X_und, y_und = tomek.fit_resample(X_und, y_und)\n",
    "    print(\"[Binary] After TomekLinks:\", Counter(y_und))\n",
    "\n",
    "    # Using PCA \n",
    "\n",
    "    #pca = PCA(n_components=5) \n",
    "    #X_und = pca.fit_transform(X_und)\n",
    "    #X_test = pca.transform(X_test_scaled)\n",
    "\n",
    "    # Baseline models\n",
    "\n",
    "    # SVM MODEL\n",
    "    svm = LinearSVC(C=10, dual=False, class_weight=\"balanced\")\n",
    "    svm.fit(X_und, y_und)\n",
    "    svm_pred = svm.predict(X_test)\n",
    "\n",
    "    # RF MODEL\n",
    "    rf = RandomForestClassifier(n_estimators=300, criterion=\"gini\", max_depth=10, n_jobs=-1, class_weight=\"balanced\")\n",
    "    rf.fit(X_und, y_und)\n",
    "    rf_pred = rf.predict(X_test)\n",
    "\n",
    "    # NN MODEL\n",
    "    model = Sequential([\n",
    "    Input(shape=(X_und.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),  \n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),  \n",
    "    Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "    classes = np.unique(y_und)\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_und)\n",
    "    class_weights = dict(zip(classes, weights))\n",
    "\n",
    "    model.fit(X_und, y_und, epochs=20, batch_size=32, validation_split=0.2, class_weight=class_weights)\n",
    "    nn_pred_probs = model.predict(X_test)\n",
    "    nn_pred = (nn_pred_probs > 0.65).astype(int)\n",
    "\n",
    "    precision_svm, recall_svm, f1_svm, _ = precision_recall_fscore_support(y_test, svm_pred, average='binary')\n",
    "    f1s_svm.append(f1_svm)\n",
    "    precisions_svm.append(precision_svm)\n",
    "    recalls_svm.append(recall_svm)\n",
    "\n",
    "    precision_rf, recall_rf, f1_rf, _ = precision_recall_fscore_support(y_test, rf_pred, average='binary')\n",
    "    f1s_rf.append(f1_rf)\n",
    "    precisions_rf.append(precision_rf)\n",
    "    recalls_rf.append(recall_rf)\n",
    "\n",
    "    precision_nn, recall_nn, f1_nn, _ = precision_recall_fscore_support(y_test, nn_pred, average='binary')\n",
    "    f1s_nn.append(f1_nn)\n",
    "    precisions_nn.append(precision_nn)\n",
    "    recalls_nn.append(recall_nn)\n",
    "\n",
    "results = {\n",
    "        \"SVM\": {\"F1\": round(np.mean(f1s_svm),2), \"Precision\": round(np.mean(precisions_svm),2), \"Recall\": round(np.mean(recalls_svm),2)},\n",
    "        \"RF\": {\"F1\": round(np.mean(f1s_rf),2), \"Precision\": round(np.mean(precisions_rf),2), \"Recall\": round(np.mean(recalls_rf),2)},\n",
    "        \"NN\": {\"F1\": round(np.mean(f1s_nn),2), \"Precision\": round(np.mean(precisions_nn),2), \"Recall\": round(np.mean(recalls_nn),2)}\n",
    "    }\n",
    "pprint(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
