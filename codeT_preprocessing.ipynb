{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d4a7fbe",
   "metadata": {},
   "source": [
    "# Checking wich is the best preprocessing methods combo - Ternary Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983cb573",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a0700e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from keras import Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2010e38b",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2cbc49f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset\n",
    "path_3 = \"datasets/diabetes_012_health_indicators_BRFSS2015.csv\"\n",
    "\n",
    "df = pd.read_csv(path_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c2d7c8",
   "metadata": {},
   "source": [
    "### Ternary Dataset preprocessing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11b7a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining duplicates: 0.\n",
      "Epoch 1/20\n",
      "\u001b[1m1299/1299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7199 - loss: 0.6462 - val_accuracy: 0.0000e+00 - val_loss: 3.0398\n",
      "Epoch 2/20\n",
      "\u001b[1m1299/1299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7925 - loss: 0.5139 - val_accuracy: 0.0000e+00 - val_loss: 3.0676\n",
      "Epoch 3/20\n",
      "\u001b[1m1299/1299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8047 - loss: 0.4923 - val_accuracy: 0.0000e+00 - val_loss: 2.9236\n",
      "Epoch 4/20\n",
      "\u001b[1m1299/1299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8050 - loss: 0.4885 - val_accuracy: 0.0000e+00 - val_loss: 2.9113\n",
      "Epoch 5/20\n",
      "\u001b[1m1299/1299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8088 - loss: 0.4763 - val_accuracy: 0.0000e+00 - val_loss: 2.7954\n",
      "Epoch 6/20\n",
      "\u001b[1m1299/1299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8111 - loss: 0.4739 - val_accuracy: 0.0000e+00 - val_loss: 3.0229\n",
      "Epoch 7/20\n",
      "\u001b[1m1299/1299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8193 - loss: 0.4671 - val_accuracy: 0.0000e+00 - val_loss: 3.1143\n",
      "Epoch 8/20\n",
      "\u001b[1m1299/1299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8157 - loss: 0.4679 - val_accuracy: 0.0000e+00 - val_loss: 2.9435\n",
      "Epoch 9/20\n",
      "\u001b[1m1299/1299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8213 - loss: 0.4532 - val_accuracy: 0.0000e+00 - val_loss: 3.0479\n",
      "Epoch 10/20\n",
      "\u001b[1m1299/1299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8227 - loss: 0.4516 - val_accuracy: 0.0000e+00 - val_loss: 3.0029\n",
      "Epoch 11/20\n",
      "\u001b[1m1299/1299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8239 - loss: 0.4512 - val_accuracy: 0.0000e+00 - val_loss: 3.1115\n",
      "Epoch 12/20\n",
      "\u001b[1m1299/1299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8254 - loss: 0.4471 - val_accuracy: 0.0000e+00 - val_loss: 3.0962\n",
      "Epoch 13/20\n",
      "\u001b[1m1299/1299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8306 - loss: 0.4432 - val_accuracy: 0.0000e+00 - val_loss: 2.9833\n",
      "Epoch 14/20\n",
      "\u001b[1m1299/1299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8253 - loss: 0.4443 - val_accuracy: 0.0000e+00 - val_loss: 2.9989\n",
      "Epoch 15/20\n",
      "\u001b[1m1299/1299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8276 - loss: 0.4454 - val_accuracy: 0.0000e+00 - val_loss: 2.9888\n",
      "Epoch 16/20\n",
      "\u001b[1m1299/1299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8260 - loss: 0.4471 - val_accuracy: 0.0000e+00 - val_loss: 3.0831\n",
      "Epoch 17/20\n",
      "\u001b[1m1299/1299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8284 - loss: 0.4407 - val_accuracy: 0.0000e+00 - val_loss: 3.0466\n",
      "Epoch 18/20\n",
      "\u001b[1m1299/1299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8279 - loss: 0.4426 - val_accuracy: 0.0000e+00 - val_loss: 3.0557\n",
      "Epoch 19/20\n",
      "\u001b[1m1299/1299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.4383 - val_accuracy: 0.0000e+00 - val_loss: 3.0205\n",
      "Epoch 20/20\n",
      "\u001b[1m1299/1299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8294 - loss: 0.4445 - val_accuracy: 0.0000e+00 - val_loss: 3.0136\n",
      "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 876us/step\n",
      "Epoch 1/20\n",
      "\u001b[1m1297/1297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7148 - loss: 0.6624 - val_accuracy: 0.0000e+00 - val_loss: 2.9470\n",
      "Epoch 2/20\n",
      "\u001b[1m1297/1297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7853 - loss: 0.5266 - val_accuracy: 0.0000e+00 - val_loss: 2.9890\n",
      "Epoch 3/20\n",
      "\u001b[1m1297/1297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7965 - loss: 0.4976 - val_accuracy: 0.0000e+00 - val_loss: 2.7509\n",
      "Epoch 4/20\n",
      "\u001b[1m1297/1297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7991 - loss: 0.4922 - val_accuracy: 0.0000e+00 - val_loss: 2.8301\n",
      "Epoch 5/20\n",
      "\u001b[1m1297/1297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8021 - loss: 0.4875 - val_accuracy: 0.0000e+00 - val_loss: 2.7423\n",
      "Epoch 6/20\n",
      "\u001b[1m1297/1297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8098 - loss: 0.4726 - val_accuracy: 0.0000e+00 - val_loss: 2.9587\n",
      "Epoch 7/20\n",
      "\u001b[1m1297/1297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8099 - loss: 0.4786 - val_accuracy: 0.0000e+00 - val_loss: 2.9192\n",
      "Epoch 8/20\n",
      "\u001b[1m1297/1297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8152 - loss: 0.4669 - val_accuracy: 0.0000e+00 - val_loss: 2.8793\n",
      "Epoch 9/20\n",
      "\u001b[1m1297/1297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8240 - loss: 0.4576 - val_accuracy: 0.0000e+00 - val_loss: 2.7829\n",
      "Epoch 10/20\n",
      "\u001b[1m1297/1297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8194 - loss: 0.4578 - val_accuracy: 0.0000e+00 - val_loss: 2.7888\n",
      "Epoch 11/20\n",
      "\u001b[1m1297/1297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8233 - loss: 0.4580 - val_accuracy: 0.0000e+00 - val_loss: 2.7511\n",
      "Epoch 12/20\n",
      "\u001b[1m1297/1297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8246 - loss: 0.4530 - val_accuracy: 0.0000e+00 - val_loss: 2.8720\n",
      "Epoch 13/20\n",
      "\u001b[1m1297/1297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8219 - loss: 0.4572 - val_accuracy: 0.0000e+00 - val_loss: 2.9575\n",
      "Epoch 14/20\n",
      "\u001b[1m1297/1297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8240 - loss: 0.4491 - val_accuracy: 0.0000e+00 - val_loss: 2.9023\n",
      "Epoch 15/20\n",
      "\u001b[1m1297/1297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8230 - loss: 0.4524 - val_accuracy: 0.0000e+00 - val_loss: 2.9243\n",
      "Epoch 16/20\n",
      "\u001b[1m1297/1297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8271 - loss: 0.4518 - val_accuracy: 0.0000e+00 - val_loss: 2.8695\n",
      "Epoch 17/20\n",
      "\u001b[1m1297/1297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8314 - loss: 0.4480 - val_accuracy: 0.0000e+00 - val_loss: 2.9037\n",
      "Epoch 18/20\n",
      "\u001b[1m1297/1297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8281 - loss: 0.4475 - val_accuracy: 0.0000e+00 - val_loss: 2.8798\n",
      "Epoch 19/20\n",
      "\u001b[1m1297/1297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8270 - loss: 0.4480 - val_accuracy: 0.0000e+00 - val_loss: 2.9282\n",
      "Epoch 20/20\n",
      "\u001b[1m1297/1297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8307 - loss: 0.4418 - val_accuracy: 0.0000e+00 - val_loss: 2.8237\n",
      "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step\n",
      "Epoch 1/20\n",
      "\u001b[1m1298/1298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7095 - loss: 0.6662 - val_accuracy: 0.0000e+00 - val_loss: 2.9865\n",
      "Epoch 2/20\n",
      "\u001b[1m1298/1298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7746 - loss: 0.5476 - val_accuracy: 0.0000e+00 - val_loss: 2.8628\n",
      "Epoch 3/20\n",
      "\u001b[1m1298/1298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7867 - loss: 0.5227 - val_accuracy: 0.0000e+00 - val_loss: 2.7983\n",
      "Epoch 4/20\n",
      "\u001b[1m1298/1298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7935 - loss: 0.5057 - val_accuracy: 0.0000e+00 - val_loss: 2.8081\n",
      "Epoch 5/20\n",
      "\u001b[1m1298/1298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7933 - loss: 0.5014 - val_accuracy: 0.0000e+00 - val_loss: 2.7943\n",
      "Epoch 6/20\n",
      "\u001b[1m1298/1298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7957 - loss: 0.5037 - val_accuracy: 0.0000e+00 - val_loss: 2.6831\n",
      "Epoch 7/20\n",
      "\u001b[1m1298/1298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7985 - loss: 0.4956 - val_accuracy: 0.0000e+00 - val_loss: 2.7307\n",
      "Epoch 8/20\n",
      "\u001b[1m1298/1298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8025 - loss: 0.4843 - val_accuracy: 0.0000e+00 - val_loss: 2.8422\n",
      "Epoch 9/20\n",
      "\u001b[1m1298/1298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8051 - loss: 0.4883 - val_accuracy: 0.0000e+00 - val_loss: 2.8625\n",
      "Epoch 10/20\n",
      "\u001b[1m1298/1298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8076 - loss: 0.4837 - val_accuracy: 0.0000e+00 - val_loss: 2.8610\n",
      "Epoch 11/20\n",
      "\u001b[1m1298/1298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8107 - loss: 0.4801 - val_accuracy: 0.0000e+00 - val_loss: 2.7984\n",
      "Epoch 12/20\n",
      "\u001b[1m1298/1298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8125 - loss: 0.4779 - val_accuracy: 0.0000e+00 - val_loss: 2.9154\n",
      "Epoch 13/20\n",
      "\u001b[1m1298/1298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8106 - loss: 0.4779 - val_accuracy: 0.0000e+00 - val_loss: 2.7137\n",
      "Epoch 14/20\n",
      "\u001b[1m1298/1298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8084 - loss: 0.4775 - val_accuracy: 0.0000e+00 - val_loss: 2.8989\n",
      "Epoch 15/20\n",
      "\u001b[1m1298/1298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8135 - loss: 0.4729 - val_accuracy: 0.0000e+00 - val_loss: 2.9065\n",
      "Epoch 16/20\n",
      "\u001b[1m1298/1298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8113 - loss: 0.4819 - val_accuracy: 0.0000e+00 - val_loss: 2.7864\n",
      "Epoch 17/20\n",
      "\u001b[1m1298/1298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8147 - loss: 0.4733 - val_accuracy: 0.0000e+00 - val_loss: 2.8942\n",
      "Epoch 18/20\n",
      "\u001b[1m1298/1298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8143 - loss: 0.4695 - val_accuracy: 0.0000e+00 - val_loss: 2.8552\n",
      "Epoch 19/20\n",
      "\u001b[1m1298/1298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8152 - loss: 0.4735 - val_accuracy: 0.0000e+00 - val_loss: 2.8443\n",
      "Epoch 20/20\n",
      "\u001b[1m1298/1298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8125 - loss: 0.4734 - val_accuracy: 0.0000e+00 - val_loss: 2.7877\n",
      "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step\n",
      "Epoch 1/20\n",
      "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7363 - loss: 0.6451 - val_accuracy: 0.0000e+00 - val_loss: 2.6955\n",
      "Epoch 2/20\n",
      "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7822 - loss: 0.5335 - val_accuracy: 0.0000e+00 - val_loss: 3.0318\n",
      "Epoch 3/20\n",
      "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7892 - loss: 0.5100 - val_accuracy: 0.0000e+00 - val_loss: 2.6603\n",
      "Epoch 4/20\n",
      "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7964 - loss: 0.5006 - val_accuracy: 0.0000e+00 - val_loss: 2.8848\n",
      "Epoch 5/20\n",
      "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7975 - loss: 0.4954 - val_accuracy: 0.0000e+00 - val_loss: 2.8870\n",
      "Epoch 6/20\n",
      "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8046 - loss: 0.4850 - val_accuracy: 0.0000e+00 - val_loss: 2.8779\n",
      "Epoch 7/20\n",
      "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8094 - loss: 0.4756 - val_accuracy: 0.0000e+00 - val_loss: 2.8215\n",
      "Epoch 8/20\n",
      "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8137 - loss: 0.4695 - val_accuracy: 0.0000e+00 - val_loss: 2.7277\n",
      "Epoch 9/20\n",
      "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8178 - loss: 0.4624 - val_accuracy: 0.0000e+00 - val_loss: 2.7186\n",
      "Epoch 10/20\n",
      "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8193 - loss: 0.4664 - val_accuracy: 0.0000e+00 - val_loss: 2.8634\n",
      "Epoch 11/20\n",
      "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8205 - loss: 0.4649 - val_accuracy: 0.0000e+00 - val_loss: 2.8650\n",
      "Epoch 12/20\n",
      "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8186 - loss: 0.4614 - val_accuracy: 0.0000e+00 - val_loss: 2.9011\n",
      "Epoch 13/20\n",
      "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8193 - loss: 0.4640 - val_accuracy: 0.0000e+00 - val_loss: 2.9069\n",
      "Epoch 14/20\n",
      "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8213 - loss: 0.4577 - val_accuracy: 0.0000e+00 - val_loss: 2.8171\n",
      "Epoch 15/20\n",
      "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8205 - loss: 0.4609 - val_accuracy: 0.0000e+00 - val_loss: 2.8528\n",
      "Epoch 16/20\n",
      "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8200 - loss: 0.4584 - val_accuracy: 0.0000e+00 - val_loss: 2.8653\n",
      "Epoch 17/20\n",
      "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8242 - loss: 0.4571 - val_accuracy: 0.0000e+00 - val_loss: 2.9015\n",
      "Epoch 18/20\n",
      "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8240 - loss: 0.4540 - val_accuracy: 0.0000e+00 - val_loss: 2.8986\n",
      "Epoch 19/20\n",
      "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8190 - loss: 0.4567 - val_accuracy: 0.0000e+00 - val_loss: 2.9084\n",
      "Epoch 20/20\n",
      "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8218 - loss: 0.4597 - val_accuracy: 0.0000e+00 - val_loss: 2.9926\n",
      "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853us/step\n",
      "Epoch 1/20\n",
      "\u001b[1m1308/1308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7119 - loss: 0.6772 - val_accuracy: 0.0000e+00 - val_loss: 2.9429\n",
      "Epoch 2/20\n",
      "\u001b[1m1308/1308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7781 - loss: 0.5424 - val_accuracy: 0.0000e+00 - val_loss: 2.8891\n",
      "Epoch 3/20\n",
      "\u001b[1m1308/1308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7907 - loss: 0.5195 - val_accuracy: 0.0000e+00 - val_loss: 2.7806\n",
      "Epoch 4/20\n",
      "\u001b[1m1308/1308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7954 - loss: 0.5056 - val_accuracy: 0.0000e+00 - val_loss: 2.8448\n",
      "Epoch 5/20\n",
      "\u001b[1m1308/1308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8001 - loss: 0.4963 - val_accuracy: 0.0000e+00 - val_loss: 2.7426\n",
      "Epoch 6/20\n",
      "\u001b[1m1308/1308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7969 - loss: 0.4992 - val_accuracy: 0.0000e+00 - val_loss: 2.8439\n",
      "Epoch 7/20\n",
      "\u001b[1m1308/1308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8068 - loss: 0.4845 - val_accuracy: 0.0000e+00 - val_loss: 2.6067\n",
      "Epoch 8/20\n",
      "\u001b[1m1308/1308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8117 - loss: 0.4797 - val_accuracy: 0.0000e+00 - val_loss: 2.8181\n",
      "Epoch 9/20\n",
      "\u001b[1m1308/1308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8144 - loss: 0.4755 - val_accuracy: 0.0000e+00 - val_loss: 2.7270\n",
      "Epoch 10/20\n",
      "\u001b[1m1308/1308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8165 - loss: 0.4690 - val_accuracy: 0.0000e+00 - val_loss: 2.8393\n",
      "Epoch 11/20\n",
      "\u001b[1m1308/1308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8161 - loss: 0.4713 - val_accuracy: 0.0000e+00 - val_loss: 2.9431\n",
      "Epoch 12/20\n",
      "\u001b[1m1308/1308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8194 - loss: 0.4678 - val_accuracy: 0.0000e+00 - val_loss: 2.9296\n",
      "Epoch 13/20\n",
      "\u001b[1m1308/1308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8175 - loss: 0.4690 - val_accuracy: 0.0000e+00 - val_loss: 2.8665\n",
      "Epoch 14/20\n",
      "\u001b[1m1308/1308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8238 - loss: 0.4560 - val_accuracy: 0.0000e+00 - val_loss: 2.8017\n",
      "Epoch 15/20\n",
      "\u001b[1m1308/1308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8214 - loss: 0.4635 - val_accuracy: 0.0000e+00 - val_loss: 2.8611\n",
      "Epoch 16/20\n",
      "\u001b[1m1308/1308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8186 - loss: 0.4632 - val_accuracy: 0.0000e+00 - val_loss: 2.9097\n",
      "Epoch 17/20\n",
      "\u001b[1m1308/1308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8218 - loss: 0.4578 - val_accuracy: 0.0000e+00 - val_loss: 2.9152\n",
      "Epoch 18/20\n",
      "\u001b[1m1308/1308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8202 - loss: 0.4643 - val_accuracy: 0.0000e+00 - val_loss: 2.8342\n",
      "Epoch 19/20\n",
      "\u001b[1m1308/1308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8212 - loss: 0.4592 - val_accuracy: 0.0000e+00 - val_loss: 2.8751\n",
      "Epoch 20/20\n",
      "\u001b[1m1308/1308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8232 - loss: 0.4634 - val_accuracy: 0.0000e+00 - val_loss: 2.9115\n",
      "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step\n",
      "{'NN': {'F1': np.float64(0.19),\n",
      "        'Precision': np.float64(0.33),\n",
      "        'Recall': np.float64(0.42)},\n",
      " 'RF': {'F1': np.float64(0.38),\n",
      "        'Precision': np.float64(0.44),\n",
      "        'Recall': np.float64(0.48)},\n",
      " 'SVM': {'F1': np.float64(0.36),\n",
      "         'Precision': np.float64(0.45),\n",
      "         'Recall': np.float64(0.47)}}\n"
     ]
    }
   ],
   "source": [
    "# Removing duplicates\n",
    "\n",
    "df.drop_duplicates(inplace = True)\n",
    "print(f\"Remaining duplicates: {df.duplicated().sum()}.\")\n",
    "\n",
    "# Droping columns that are not relevant for the model\n",
    "\n",
    "columns = [\"PhysHlth\",\"Veggies\",\"NoDocbcCost\"]\n",
    "df = df.drop(columns=columns)\n",
    "\n",
    "# PREPARING THE DATA BEFORE AND AFTER THE DATA SPLITTING\n",
    "\n",
    "X = df.drop(columns=['Diabetes_012'])\n",
    "y = df['Diabetes_012']\n",
    "\n",
    "\n",
    "f1s_svm, precisions_svm, recalls_svm = [], [], []\n",
    "f1s_rf, precisions_rf, recalls_rf = [], [], []\n",
    "f1s_nn, precisions_nn, recalls_nn = [], [], []\n",
    "\n",
    "n_runs = 5\n",
    "for run in range(n_runs):\n",
    "\n",
    "    # Spltting the data\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=run)\n",
    "\n",
    "    # Doing Normalization after splitting to avoid data leakage\n",
    "\n",
    "    #scaler = MinMaxScaler()\n",
    "    #X_train_scaled = scaler.fit_transform(X_train)\n",
    "    #X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Doing Standardization \n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Random Undersampling\n",
    "\n",
    "    undersample = RandomUnderSampler(sampling_strategy={0.0:35000}, random_state=run)\n",
    "    X_und, y_und = undersample.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "    # SMOTE ENN for oversampling/downsampling\n",
    "\n",
    "    smote_enn = SMOTEENN(random_state=run, n_jobs=-1, sampling_strategy=\"auto\")\n",
    "    X_und, y_und = smote_enn.fit_resample(X_und, y_und)\n",
    "\n",
    "\n",
    "    # SMOTE for Oversampling\n",
    "\n",
    "    #smote = SMOTE(random_state=run, sampling_strategy=\"auto\")\n",
    "    #X_und, y_und = smote.fit_resample(X_und, y_und)\n",
    "\n",
    "    # Tomek Links\n",
    "\n",
    "    tomek = TomekLinks()\n",
    "    X_und, y_und = tomek.fit_resample(X_und, y_und)\n",
    "    # Using PCA \n",
    "\n",
    "    pca = PCA(n_components=7) \n",
    "    X_und = pca.fit_transform(X_und)\n",
    "    X_test = pca.transform(X_test_scaled)\n",
    "\n",
    "    # Baseline models\n",
    "\n",
    "    # SVM MODEL\n",
    "    svm = LinearSVC(C=10, dual=False, class_weight=\"balanced\", multi_class='ovr')\n",
    "    svm.fit(X_und, y_und)\n",
    "    svm_pred = svm.predict(X_test)\n",
    "\n",
    "    #y_und_cat = to_categorical(y_und, num_classes=3)\n",
    "\n",
    "    # RF MODEL\n",
    "    rf = RandomForestClassifier(n_estimators=200, criterion=\"gini\", max_depth=10, n_jobs=-1, class_weight=\"balanced\")\n",
    "    rf.fit(X_und, y_und)\n",
    "    rf_pred = rf.predict(X_test)\n",
    "\n",
    "    # NN MODEL\n",
    "    model = Sequential([\n",
    "    Input(shape=(X_und.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),  \n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),  \n",
    "    Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_und, y_und, epochs=20, batch_size=32, validation_split=0.2)\n",
    "    nn_pred_probs = model.predict(X_test)\n",
    "    nn_pred = np.argmax(nn_pred_probs, axis=1)\n",
    "\n",
    "    precision_svm, recall_svm, f1_svm, _ = precision_recall_fscore_support(y_test, svm_pred, zero_division=0)\n",
    "    f1s_svm.append(f1_svm)\n",
    "    precisions_svm.append(precision_svm)\n",
    "    recalls_svm.append(recall_svm)\n",
    "\n",
    "    precision_rf, recall_rf, f1_rf, _ = precision_recall_fscore_support(y_test, rf_pred, zero_division=0)\n",
    "    f1s_rf.append(f1_rf)\n",
    "    precisions_rf.append(precision_rf)\n",
    "    recalls_rf.append(recall_rf)\n",
    "\n",
    "    precision_nn, recall_nn, f1_nn, _ = precision_recall_fscore_support(y_test, nn_pred, zero_division=0)\n",
    "    f1s_nn.append(f1_nn)\n",
    "    precisions_nn.append(precision_nn)\n",
    "    recalls_nn.append(recall_nn)\n",
    "\n",
    "results = {\n",
    "        \"SVM\": {\"F1\": round(np.mean(f1s_svm),2), \"Precision\": round(np.mean(precisions_svm),2), \"Recall\": round(np.mean(recalls_svm),2)},\n",
    "        \"RF\": {\"F1\": round(np.mean(f1s_rf),2), \"Precision\": round(np.mean(precisions_rf),2), \"Recall\": round(np.mean(recalls_rf),2)},\n",
    "        \"NN\": {\"F1\": round(np.mean(f1s_nn),2), \"Precision\": round(np.mean(precisions_nn),2), \"Recall\": round(np.mean(recalls_nn),2)}\n",
    "    }\n",
    "pprint(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
