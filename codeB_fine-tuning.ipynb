{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Packages and Inicial Data Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay,precision_recall_fscore_support, make_scorer, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset and handle a subset of it\n",
    "\n",
    "df = pd.read_csv(\"US_Accidents_March23_sampled_500k.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Severity</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Start_Lng</th>\n",
       "      <th>Distance(mi)</th>\n",
       "      <th>Visibility(mi)</th>\n",
       "      <th>Wind_Speed(mph)</th>\n",
       "      <th>Weather_Condition</th>\n",
       "      <th>Amenity</th>\n",
       "      <th>Bump</th>\n",
       "      <th>Crossing</th>\n",
       "      <th>...</th>\n",
       "      <th>Stop</th>\n",
       "      <th>Traffic_Calming</th>\n",
       "      <th>Traffic_Signal</th>\n",
       "      <th>Turning_Loop</th>\n",
       "      <th>Duration(min)</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30.641211</td>\n",
       "      <td>-91.153481</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>45.033333</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>38.990562</td>\n",
       "      <td>-77.399070</td>\n",
       "      <td>0.056</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>139.650000</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>34.661189</td>\n",
       "      <td>-120.492822</td>\n",
       "      <td>0.022</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>129.750000</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>43.680592</td>\n",
       "      <td>-92.993317</td>\n",
       "      <td>1.054</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Snow</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>120.316667</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.395484</td>\n",
       "      <td>-118.985176</td>\n",
       "      <td>0.046</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>147.150000</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Severity  Start_Lat   Start_Lng  Distance(mi)  Visibility(mi)  \\\n",
       "0         0  30.641211  -91.153481         0.000            10.0   \n",
       "1         0  38.990562  -77.399070         0.056            10.0   \n",
       "2         0  34.661189 -120.492822         0.022            10.0   \n",
       "3         0  43.680592  -92.993317         1.054            10.0   \n",
       "4         0  35.395484 -118.985176         0.046            10.0   \n",
       "\n",
       "   Wind_Speed(mph) Weather_Condition  Amenity   Bump  Crossing  ...   Stop  \\\n",
       "0              5.0             Clear    False  False     False  ...  False   \n",
       "1              5.0             Clear    False  False     False  ...  False   \n",
       "2             13.0             Clear    False  False     False  ...  False   \n",
       "3             15.0              Snow    False  False     False  ...  False   \n",
       "4              0.0             Clear    False  False     False  ...  False   \n",
       "\n",
       "   Traffic_Calming  Traffic_Signal  Turning_Loop  Duration(min)  Year  Month  \\\n",
       "0            False            True         False      45.033333  2019      6   \n",
       "1            False           False         False     139.650000  2022     12   \n",
       "2            False            True         False     129.750000  2022      8   \n",
       "3            False           False         False     120.316667  2022      2   \n",
       "4            False           False         False     147.150000  2020     12   \n",
       "\n",
       "   Weekday  Day  Hour  \n",
       "0        2   12    10  \n",
       "1        5    3    23  \n",
       "2        5   20    13  \n",
       "3        0   21    17  \n",
       "4        4    4     1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Droping columns that are not relevant for the model\n",
    "\n",
    "columns = ['ID','Source','End_Lat','End_Lng','End_Time','Start_Time','Description','Airport_Code','Country','Weather_Timestamp',\n",
    "           'Civil_Twilight','Nautical_Twilight','Astronomical_Twilight','Timezone','Wind_Direction','Pressure(in)','Zipcode',\n",
    "           'Precipitation(in)','Humidity(%)','Wind_Chill(F)','Temperature(F)','Sunrise_Sunset','Street','County',\n",
    "           'State','City']\n",
    "df1 = df.drop(columns=columns)\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data before and after the Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  First Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before balancing: Counter({0: 402416, 1: 97584})\n"
     ]
    }
   ],
   "source": [
    "# Checking the class distribution before balancing\n",
    "print(\"Before balancing:\", Counter(df1['Severity']))\n",
    "\n",
    "X = df1.drop(columns=['Severity'])\n",
    "y = df1['Severity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Balancing and Undersampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Undersampling: Counter({0: 139405, 1: 97584})\n"
     ]
    }
   ],
   "source": [
    "# Random Undersampling first to reduce dataset size\n",
    "\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.7, random_state=17)\n",
    "X_resampled, y_resampled = undersample.fit_resample(X, y)\n",
    "\n",
    "print(\"After Undersampling:\", Counter(y_resampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Splitting into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tomek Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Tomek Links: Counter({0: 111753, 1: 77838})\n"
     ]
    }
   ],
   "source": [
    "# Apply Tomek Links to get better class separation\n",
    "# Try to not do this step and see if the results get better/worse\n",
    "\n",
    "tomek = TomekLinks()\n",
    "X_tomek, y_tomek = tomek.fit_resample(X_train_encoded, y_train)  \n",
    "\n",
    "print(\"After Tomek Links:\", Counter(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Standardized the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing Standardization after splitting to avoid data leakage\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_tomek)\n",
    "X_test_scaled = scaler.transform(X_test_encoded) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PCA on the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PCA \n",
    "\n",
    "pca = PCA(n_components=20) \n",
    "\n",
    "X_train_scaled = pca.fit_transform(X_train_scaled)\n",
    "X_test_scaled = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Hyperparameter Tuning With Optuna Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearch for Decision Tree...\n",
      "Running GridSearch for KNN...\n",
      "Running GridSearch for NaÃ¯ve Bayes...\n",
      "{'Decision Tree': {'Accuracy': np.float64(0.6949839885132318),\n",
      "                   'Best Model': DecisionTreeClassifier(max_depth=11, min_samples_leaf=2),\n",
      "                   'Best Parameters': {'max_depth': 11,\n",
      "                                       'min_samples_leaf': 2,\n",
      "                                       'min_samples_split': 2},\n",
      "                   'F1-score': np.float64(0.6948744131047853),\n",
      "                   'Precision': np.float64(0.6948729047893455),\n",
      "                   'Recall': np.float64(0.6949839885132318)},\n",
      " 'KNN': {'Accuracy': np.float64(0.727098730544232),\n",
      "         'Best Model': KNeighborsClassifier(metric='euclidean', n_neighbors=19, weights='distance'),\n",
      "         'Best Parameters': {'metric': 'euclidean',\n",
      "                             'n_neighbors': 19,\n",
      "                             'weights': 'distance'},\n",
      "         'F1-score': np.float64(0.7265706639647359),\n",
      "         'Precision': np.float64(0.7263686612909024),\n",
      "         'Recall': np.float64(0.727098730544232)},\n",
      " 'NaÃ¯ve Bayes': {'Accuracy': np.float64(0.5172250598091802),\n",
      "                 'Best Model': GaussianNB(),\n",
      "                 'Best Parameters': 'Default Parameters',\n",
      "                 'F1-score': np.float64(0.45175777925517735),\n",
      "                 'Precision': np.float64(0.6323541748647536),\n",
      "                 'Recall': np.float64(0.5172250598091802)}}\n"
     ]
    }
   ],
   "source": [
    "# Defining tuning optimization for SVM\n",
    "\n",
    "def objective_svc(trial):\n",
    "    params = {\n",
    "        \"C\": trial.suggest_loguniform(\"C\", 1e-3, 100),\n",
    "        \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-4, 1e-1),\n",
    "        \"kernel\": \"rbf\", \"linear\"\n",
    "        \"class_weight\": \"balanced\",\n",
    "        \"probability\": True\n",
    "    }\n",
    "\n",
    "    model = SVC(**params)\n",
    "\n",
    "    scores = cross_validate(model, X_train_scaled2, y_resampled2, scoring=scoring, cv=cv)\n",
    "    return scores[\"test_accuracy\"].mean(), scores[\"test_precision\"].mean(), scores[\"test_recall\"].mean()\n",
    "\n",
    "study_svc = optuna.create_study(directions=[\"maximize\", \"maximize\", \"maximize\"], study_name=\"SVC\")\n",
    "study_svc.optimize(objective_svc, n_trials=30)\n",
    "\n",
    "vis.plot_pareto_front(study_svc, target_names=[\"Accuracy\", \"Precision\", \"Recall\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining tuning optimization for RF\n",
    "\n",
    "def objective_rf(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 5, 20),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 5),\n",
    "        \"class_weight\": \"balanced\",\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "\n",
    "    model = RandomForestClassifier(**params)\n",
    "\n",
    "    scores = cross_validate(model, X_train_scaled2, y_resampled2, scoring=scoring, cv=cv)\n",
    "    return scores[\"test_accuracy\"].mean(), scores[\"test_precision\"].mean(), scores[\"test_recall\"].mean()\n",
    "\n",
    "study_rf = optuna.create_study(directions=[\"maximize\", \"maximize\", \"maximize\"], study_name=\"RF\")\n",
    "study_rf.optimize(objective_rf, n_trials=30)\n",
    "\n",
    "vis.plot_pareto_front(study_rf, target_names=[\"Accuracy\", \"Precision\", \"Recall\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining tuning optimization for NN\n",
    "\n",
    "def create_model(trial):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(trial.suggest_int(\"units1\", 64, 256), activation=\"relu\", input_shape=(X_train_scaled2.shape[1],)))\n",
    "    model.add(Dropout(trial.suggest_float(\"dropout1\", 0.2, 0.5)))\n",
    "\n",
    "    for i in range(trial.suggest_int(\"n_layers\", 1, 3)):\n",
    "        model.add(Dense(trial.suggest_int(f\"units_{i}\", 32, 128), activation=\"relu\"))\n",
    "        model.add(Dropout(trial.suggest_float(f\"dropout_{i}\", 0.2, 0.5)))\n",
    "\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=trial.suggest_loguniform(\"lr\", 1e-4, 1e-2)),\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\", \"precision\", \"recall\"])\n",
    "    return model\n",
    "\n",
    "def objective_nn(trial):\n",
    "    n_units1 = trial.suggest_int(\"n_units1\", 32, 128)\n",
    "    n_units2 = trial.suggest_int(\"n_units2\", 16, 64)\n",
    "    dropout1 = trial.suggest_float(\"dropout1\", 0.2, 0.6)\n",
    "    dropout2 = trial.suggest_float(\"dropout2\", 0.2, 0.6)\n",
    "    learning_rate = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "    epochs = 20\n",
    "\n",
    "    model = KerasClassifier(\n",
    "        lambda: create_model(n_units1, n_units2, dropout1, dropout2, learning_rate),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    classes = np.unique(y_resampled2)\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_resampled2)\n",
    "    class_weights = dict(zip(classes, weights))\n",
    "\n",
    "    scores = cross_validate(model, X_train_scaled2, y_resampled2,\n",
    "                            scoring=scoring, cv=cv, fit_params={\"class_weight\": class_weights})\n",
    "\n",
    "    return scores[\"test_accuracy\"].mean(), scores[\"test_precision\"].mean(), scores[\"test_recall\"].mean()\n",
    "\n",
    "study_nn = optuna.create_study(directions=[\"maximize\", \"maximize\", \"maximize\"], study_name=\"NN\")\n",
    "study_nn.optimize(objective_nn, n_trials=30)\n",
    "\n",
    "vis.plot_pareto_front(study_nn, target_names=[\"Accuracy\", \"Precision\", \"Recall\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KNeighborsClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mKNeighborsClassifier\u001b[49m(metric=\u001b[33m'\u001b[39m\u001b[33meuclidean\u001b[39m\u001b[33m'\u001b[39m, n_neighbors=\u001b[32m19\u001b[39m, weights=\u001b[33m'\u001b[39m\u001b[33mdistance\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m model.fit(X_train_scaled, y_tomek)\n\u001b[32m      3\u001b[39m y_pred_model = model.predict(X_test_scaled)\n",
      "\u001b[31mNameError\u001b[39m: name 'KNeighborsClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Best parameters for each model\n",
    "\n",
    "best_trial_svm = max(study_svc.best_trials, key=lambda t: sum(t.values))\n",
    "print(\"SVC Best Params:\", best_trial_svm.params)\n",
    "print(\"Accuracy:\", best_trial_svm.values[0])\n",
    "print(\"Precision:\", best_trial_svm.values[1])\n",
    "print(\"Recall:\", best_trial_svm.values[2])\n",
    "\n",
    "best_trial_rf = max(study_rf.best_trials, key=lambda t: sum(t.values))\n",
    "print(\"SVC Best Params:\", best_trial_rf.params)\n",
    "print(\"Accuracy:\", best_trial_rf.values[0])\n",
    "print(\"Precision:\", best_trial_rf.values[1])\n",
    "print(\"Recall:\", best_trial_rf.values[2])\n",
    "\n",
    "best_trial_nn = max(study_nn.best_trials, key=lambda t: sum(t.values))\n",
    "print(\"SVC Best Params:\", best_trial_nn.params)\n",
    "print(\"Accuracy:\", best_trial_nn.values[0])\n",
    "print(\"Precision:\", best_trial_nn.values[1])\n",
    "print(\"Recall:\", best_trial_nn.values[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model and the parameters tuned\n",
    "print(\"The best model obtained (SVC) and it's params:\", best_trial_svc.params)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_model)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
